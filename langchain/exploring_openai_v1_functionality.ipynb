{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudarshan-koirala/youtube-stuffs/blob/main/langchain/exploring_openai_v1_functionality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f970f757-ec76-4bf0-90cd-a2fb68b945e3",
      "metadata": {
        "id": "f970f757-ec76-4bf0-90cd-a2fb68b945e3"
      },
      "source": [
        "# Exploring OpenAI V1 functionality\n",
        "\n",
        "On 11.06.23 OpenAI released a number of new features, and along with it bumped their Python SDK to 1.0.0. This notebook shows off the new features and how to use them with LangChain."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries and Env Setup"
      ],
      "metadata": {
        "id": "E7DEX5VW0Af3"
      },
      "id": "E7DEX5VW0Af3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee897729-263a-4073-898f-bb4cf01ed829",
      "metadata": {
        "id": "ee897729-263a-4073-898f-bb4cf01ed829"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# need openai>=1.1.0, langchain>=0.0.335, langchain-experimental>=0.0.39\n",
        "!pip install -U openai langchain watermark langchain-experimental"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext watermark\n",
        "%watermark -a \"Sudarshan Koirala\" -vmp langchain,openai"
      ],
      "metadata": {
        "id": "jnun6OKAzIz5"
      },
      "id": "jnun6OKAzIz5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# https://platform.openai.com/account/api-keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "wb65wW14z5Tw"
      },
      "id": "wb65wW14z5Tw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fa7e7e95-90a1-4f73-98fe-10c4b4e0951b",
      "metadata": {
        "id": "fa7e7e95-90a1-4f73-98fe-10c4b4e0951b"
      },
      "source": [
        "## [Vision](https://platform.openai.com/docs/guides/vision)\n",
        "\n",
        "OpenAI released multi-modal models, which can take a sequence of text and images as input."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "display.Image(\"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/langchain_stack.png\", width=600)"
      ],
      "metadata": {
        "id": "iYtXONxcY_u_"
      },
      "id": "iYtXONxcY_u_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3e067ce-7a43-47a7-bc89-41f1de4cf136",
      "metadata": {
        "id": "c3e067ce-7a43-47a7-bc89-41f1de4cf136"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.messages import HumanMessage, SystemMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c8c3965-d3c9-4186-b5f3-5e67855ef916",
      "metadata": {
        "id": "1c8c3965-d3c9-4186-b5f3-5e67855ef916"
      },
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=256)\n",
        "chat.invoke(\n",
        "    [\n",
        "        HumanMessage(\n",
        "            content=[\n",
        "                {\"type\": \"text\", \"text\": \"What is this image showing\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/langchain_stack.png\",\n",
        "                        \"detail\": \"auto\",\n",
        "                    },\n",
        "                },\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "210f8248-fcf3-4052-a4a3-0684e08f8785",
      "metadata": {
        "id": "210f8248-fcf3-4052-a4a3-0684e08f8785"
      },
      "source": [
        "## [OpenAI assistants](https://platform.openai.com/docs/assistants/overview)\n",
        "\n",
        "> The Assistants API allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function calling\n",
        "\n",
        "\n",
        "You can interact with OpenAI Assistants using OpenAI tools or custom tools. When using exclusively OpenAI tools, you can just invoke the assistant directly and get final answers. When using custom tools, you can run the assistant and tool execution loop using the built-in AgentExecutor or easily write your own executor.\n",
        "\n",
        "Below we show the different ways to interact with Assistants. As a simple example, let's build a math tutor that can write and run code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318da28d-4cec-42ab-ae3e-76d95bb34fa5",
      "metadata": {
        "id": "318da28d-4cec-42ab-ae3e-76d95bb34fa5"
      },
      "source": [
        "## Using only OpenAI tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9064bbe-d9f7-4a29-a7b3-73933b3197e7",
      "metadata": {
        "id": "a9064bbe-d9f7-4a29-a7b3-73933b3197e7"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.openai_assistant import OpenAIAssistantRunnable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a20a008-49ac-46d2-aa26-b270118af5ea",
      "metadata": {
        "id": "7a20a008-49ac-46d2-aa26-b270118af5ea"
      },
      "outputs": [],
      "source": [
        "interpreter_assistant = OpenAIAssistantRunnable.create_assistant(\n",
        "    name=\"langchain assistant\",\n",
        "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
        "    tools=[{\"type\": \"code_interpreter\"}],\n",
        "    model=\"gpt-4-1106-preview\",\n",
        ")\n",
        "output = interpreter_assistant.invoke({\"content\": \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "pprint(str(output))"
      ],
      "metadata": {
        "id": "Ww2la2jp1RaT"
      },
      "id": "Ww2la2jp1RaT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a8ddd181-ac63-4ab6-a40d-a236120379c1",
      "metadata": {
        "id": "a8ddd181-ac63-4ab6-a40d-a236120379c1"
      },
      "source": [
        "## As a LangChain agent with arbitrary tools\n",
        "\n",
        "Now let's recreate this functionality using our own tools. For this example we'll use the [E2B sandbox runtime tool](https://e2b.dev/docs?ref=landing-page-get-started)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee4cc355-f2d6-4c51-bcf7-f502868357d3",
      "metadata": {
        "id": "ee4cc355-f2d6-4c51-bcf7-f502868357d3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install e2b duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48681ac7-b267-48d4-972c-8a7df8393a21",
      "metadata": {
        "id": "48681ac7-b267-48d4-972c-8a7df8393a21"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun, E2BDataAnalysisTool\n",
        "\n",
        "# https://e2b.dev/docs\n",
        "tools = [E2BDataAnalysisTool(api_key=\"E2B_API_KEY\"), DuckDuckGoSearchRun()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c01dd79-dd3e-4509-a2e2-009a7f99f16a",
      "metadata": {
        "id": "1c01dd79-dd3e-4509-a2e2-009a7f99f16a"
      },
      "outputs": [],
      "source": [
        "agent = OpenAIAssistantRunnable.create_assistant(\n",
        "    name=\"langchain assistant e2b tool\",\n",
        "    instructions=\"You are a personal math tutor. Write and run code to answer math questions. You can also search the internet.\",\n",
        "    tools=tools,\n",
        "    model=\"gpt-4-1106-preview\",\n",
        "    as_agent=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ac71d8b-4b4b-4f98-b826-6b3c57a34166",
      "metadata": {
        "id": "1ac71d8b-4b4b-4f98-b826-6b3c57a34166"
      },
      "source": [
        "#### Using AgentExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f137f94-801f-4766-9ff5-2de9df5e8079",
      "metadata": {
        "id": "1f137f94-801f-4766-9ff5-2de9df5e8079"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "agent_executor.invoke({\"content\": \"What's the weather in Helsinki today divided by 2.0\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "# answer will be in Fahrenheit. Lets ask it in Celsius.\n",
        "response = agent_executor.invoke({\"content\": \"What's the weather in Helsinki today in Celsius divided by 2.0.\"})"
      ],
      "metadata": {
        "id": "ic6Ftfd43ckb"
      },
      "id": "ic6Ftfd43ckb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2d0a0b1d-c1b3-4b50-9dce-1189b51a6206",
      "metadata": {
        "id": "2d0a0b1d-c1b3-4b50-9dce-1189b51a6206"
      },
      "source": [
        "#### Custom execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b76cb669-6aba-4827-868f-00aa960026f2",
      "metadata": {
        "id": "b76cb669-6aba-4827-868f-00aa960026f2"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.agent import AgentFinish\n",
        "\n",
        "# its easier this way to pass the thread it down the line as we proceed\n",
        "\n",
        "def execute_agent(agent, tools, input):\n",
        "    tool_map = {tool.name: tool for tool in tools}\n",
        "    response = agent.invoke(input)\n",
        "    while not isinstance(response, AgentFinish):\n",
        "        tool_outputs = []\n",
        "        for action in response:\n",
        "            tool_output = tool_map[action.tool].invoke(action.tool_input)\n",
        "            print(action.tool, action.tool_input, tool_output, end=\"\\n\\n\")\n",
        "            tool_outputs.append(\n",
        "                {\"output\": tool_output, \"tool_call_id\": action.tool_call_id}\n",
        "            )\n",
        "        response = agent.invoke(\n",
        "            {\n",
        "                \"tool_outputs\": tool_outputs,\n",
        "                \"run_id\": action.run_id,\n",
        "                \"thread_id\": action.thread_id,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7946116a-b82f-492e-835e-ca958a8949a5",
      "metadata": {
        "id": "7946116a-b82f-492e-835e-ca958a8949a5"
      },
      "outputs": [],
      "source": [
        "response = execute_agent(agent, tools, {\"content\": \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"})\n",
        "print(response.return_values[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Passing the earlier thread id to the next response."
      ],
      "metadata": {
        "id": "FADZY2s5yJIY"
      },
      "id": "FADZY2s5yJIY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2744a56-9f4f-4899-827a-fa55821c318c",
      "metadata": {
        "id": "f2744a56-9f4f-4899-827a-fa55821c318c"
      },
      "outputs": [],
      "source": [
        "next_response = execute_agent(\n",
        "    agent, tools, {\"content\": \"now add 2.241\", \"thread_id\": response.thread_id}\n",
        ")\n",
        "print(next_response.return_values[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7idSXVWA51xU"
      },
      "id": "7idSXVWA51xU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "71c34763-d1e7-4b9a-a9d7-3e4cc0dfc2c4",
      "metadata": {
        "id": "71c34763-d1e7-4b9a-a9d7-3e4cc0dfc2c4"
      },
      "source": [
        "## [JSON mode](https://platform.openai.com/docs/guides/text-generation/json-mode)\n",
        "\n",
        "Constrain the model to only generate valid JSON. Note that you must include a system message with instructions to use JSON for this mode to work.\n",
        "\n",
        "Only works with certain models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db6072c4-f3f3-415d-872b-71ea9f3c02bb",
      "metadata": {
        "id": "db6072c4-f3f3-415d-872b-71ea9f3c02bb"
      },
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\").bind(\n",
        "    response_format={\"type\": \"json_object\"}\n",
        ")\n",
        "\n",
        "output = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(\n",
        "            content=\"Extract the 'name' and 'origin' of any companies mentioned in the following statement. Return a JSON list.\"\n",
        "        ),\n",
        "        HumanMessage(\n",
        "            content=\"Google was founded in the USA, while Deepmind was founded in the UK\"\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e00ccf-b991-4249-846b-9500a0ccbfa0",
      "metadata": {
        "id": "08e00ccf-b991-4249-846b-9500a0ccbfa0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "json.loads(output.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49944887-3972-497e-8da2-6d32d44345a9",
      "metadata": {
        "id": "49944887-3972-497e-8da2-6d32d44345a9"
      },
      "source": [
        "## Tools\n",
        "\n",
        "Use tools for parallel function calling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "916292d8-0f89-40a6-af1c-5a1122327de8",
      "metadata": {
        "id": "916292d8-0f89-40a6-af1c-5a1122327de8"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain.utils.openai_functions import convert_pydantic_to_openai_tool\n",
        "\n",
        "\n",
        "class GetCurrentWeather(BaseModel):\n",
        "    \"\"\"Get the current weather in a location.\"\"\"\n",
        "\n",
        "    location: str = Field(description=\"The city and country, e.g. Kathmandu, NPL\")\n",
        "    unit: Literal[\"celsius\", \"fahrenheit\"] = Field(\n",
        "        default=\"celsius\", description=\"The temperature unit, default to celsius\"\n",
        "    )\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"You are a helpful assistant\"), (\"user\", \"{input}\")]\n",
        ")\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\").bind(\n",
        "    tools=[convert_pydantic_to_openai_tool(GetCurrentWeather)]\n",
        ")\n",
        "chain = prompt | model | PydanticToolsParser(tools=[GetCurrentWeather])\n",
        "\n",
        "chain.invoke({\"input\": \"what's the weather in KTM, SF and HEL\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Play around, trial and error needed, the way we interact might differ as the field of AI and how we interact is changing drastically."
      ],
      "metadata": {
        "id": "FXuOHzLnykJv"
      },
      "id": "FXuOHzLnykJv"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EVGWaJF6ytG6"
      },
      "id": "EVGWaJF6ytG6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "poetry-venv",
      "language": "python",
      "name": "poetry-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}